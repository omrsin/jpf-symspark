\TUsubsection{Output}
\label{subsec:module:output}

%Mention the console output of the dataset
%
%Mention the iterative datasets
%
%Mention the unfeasible path conditions

After a symbolic execution, \textit{JPF-SymSpark} produces reduced input datasets that ensure the full path coverage of the program under test. The elements in these datasets are collected during the execution and are presented to the users through the implementation of the \textit{PublisherExtension} interface provided by \jpf{}. By the means of the publisher interface, the datasets are included as part of the execution summary of \jpf{} and subsequently printed in the standard output. There are two types of datasets that can be generated as an output of the analysis depending on which strategy was chosen: the regular dataset and the iterative datasets.

\textbf{Regular dataset}

A regular dataset contains one representative element of each equivalence classes defined by the satisfiable path conditions found during the symbolic execution of the program under test. This dataset is produced when the program under test does not contain a \textit{reduce} action or the analysis was not set to conduct an iterative symbolic execution of the said operation. In such a scenario, a regular dataset is sufficient to ensure full path coverage of the program under test. The reason for this is that because no iterative analysis is required, the interrelation between the elements of the input dataset is irrelevant. 

This kind of output is sufficient when the goal of the analysis is to reason over a series of transformations. By definition, transformations in Spark have a one-to-one or one-to-many semantics (for example, \textit{filter} and \textit{flatMap} respectively) but never a many-to-one semantics as in the case of the aggregation actions. 

\textbf{Iterative datasets}

On the contrary, iterative datasets are produced when the analysis is set to conduct symbolic executions of iterative actions. In this case, the interrelation between the elements of the dataset is relevant to possible path conditions defined over accumulated values. For this reason, we decided to produce a dataset for each path condition found during the execution of the program under test, where each element of the dataset corresponds to a symbolic input that participated in the cumulative action. The cardinality of the dataset increases based on the number of iterations given that more iterations need larger datasets to actually be executed.

The result is presented as a family of datasets that comply with all the path conditions found during the execution. We decided to present all datasets and not only those corresponding to the final iteration because, although datasets of smaller iterations incur in some redundancy, it might be the case that the final iteration incurs in an unsatisfiable path condition for a path that was feasible in a previous iteration. Determining when a dataset is redundant is a future optimization.

Furthermore, an analysis can have both a regular dataset and iterative datasets as output. Although a program under test is analyzed following an iterative strategy, some transformations can break the control flow before reaching the aggregate action. This is the case of \textit{filter} transformation, where the negative branch is immediately backtracked after execution. In this scenario, a representative element for all possible path conditions that came to an end before reaching the iterative action is included in a regular dataset.

\textbf{Unsatisfiable path conditions}

Additionally, \textit{JPF-SymSpark} also reports those path conditions that were not satisfiable. This process gets triggered after a backtracking action resulting from the complete exploration of an execution path. If the path condition defining the explored path is satisfiable then a result is included in the respective dataset, otherwise the unsatisfiable path condition is reported directly to the standard output which in many cases is the executing console. Listing~\ref{lst:module:output:path-condition} shows the output corresponding to an unsatisfiable path condition of a sample program.

\begin{lstlisting}[
language=Bash,
caption={[Output for an Unsatisfiable Path Condition] Output for an unsatisfiable path condition. Values containing the word \texttt{SYMINT} respresent symbolic integers while values of the form \texttt{CONST\_X} are plain integer constants representing the number replacing the \texttt{X}. This path condition has a contradiction between the first and second elements of the conjunction.},
float,
label=lst:module:output:path-condition
]
Current path condition not satisfiable: constraint 3
v1_4_SYMINT > CONST_2 &&
(v1_4_SYMINT + CONST_1) <= CONST_3 &&
v1_1_SYMINT > CONST_2
\end{lstlisting}

The notification of unsatisfiable path conditions allows the users to identify control flow operations that could potentially represent incorrect or unexpected behavior. Altogether with the reduced input datasets, the notification of unsatisfiable path conditions provides the remaining missing part for a comprehensive analysis on the symbolic execution of a Spark program.